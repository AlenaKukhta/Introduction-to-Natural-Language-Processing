{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f838c74",
   "metadata": {},
   "source": [
    "# –ü—Ä–∞–∫—Ç–∏—á–∫—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –∫ —É—Ä–æ–∫—É 7. –°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞\n",
    "\n",
    "\n",
    "–ë–µ—Ä–µ–º –æ—Ç—ã–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ (–∏–∑ –∞—Ä—Ö–∏–≤–∞ —Å –º–∞—Ç–µ—Ä–∏–∞–ª–∞–º–∏ –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è)\n",
    "\n",
    "1. –£—á–∏–º conv —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "\n",
    "2. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å 2-–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å–µ—Ç–æ—á–µ–∫ \n",
    "\n",
    "    2.1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å tf.keras.layers.Embedding –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤–∑—è—Ç—å –∫ –ø—Ä–∏–º–µ—Ä—É —Å https://rusvectores.org/ru/\n",
    "\n",
    "    2.2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–π tf.keras.layers.Embedding –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–Ω—É —Ç–æ –µ—Å—Ç—å –≤–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞—Ç—å —Å –≤–µ—Å–∞–º–∏)\n",
    "\n",
    "–°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏ –∏ –∫–æ–≥–¥–∞ tf.keras.layers.Embedding –æ–±—É—á–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É —Å–æ –≤—Å–µ–π —Å–µ—Ç–æ—á–∫–æ–π, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ª—É—á—à–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c819360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop_words in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (2018.7.23)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b25cef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pymorphy2) (0.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7f062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: navec in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: numpy in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from navec) (1.19.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70801419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.21.0\n",
      "  Using cached numpy-1.21.0-cp39-cp39-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.21.0 which is incompatible.\n",
      "bokeh 2.4.2 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.21.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install numpy\n",
    "!pip install --upgrade numpy==1.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e731de2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.2.0\n",
      "  Downloading pandas-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl (10.7 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.7 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.2.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.2.0) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.2.0) (1.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas==1.2.0) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.4.2\n",
      "    Uninstalling pandas-1.4.2:\n",
      "      Successfully uninstalled pandas-1.4.2\n",
      "Successfully installed pandas-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab36b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.21.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2d111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alenakukhta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 100)\n",
    "import re\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from navec import Navec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279a0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2e9b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd442e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42109aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (1.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d8516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/g6jhnpm16ql1vgrrbrbd_yd00000gn/T/ipykernel_22782/3225389896.py:1: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils import traitlets as _traitlets\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils import traitlets as _traitlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00be4476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ —Å –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –¥–∏—Å–∫–∞\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d4ace73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlrd>=1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee40e74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>–í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–æ—Å—Ç—É–ø –∫ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º –≤ —Ç...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—Ç–ª–∏—á–Ω–æ –≤—Å–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ –Ω–∏–∫—É–¥–∞. –†–∞–Ω–µ–µ –±–æ–ª—å—à–µ –≥–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>–í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>–£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º–∞—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—é—Ç –∏ —Ç—É–ø—è—Ç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>–û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  \\\n",
       "0       5   \n",
       "1       4   \n",
       "2       5   \n",
       "3       5   \n",
       "4       5   \n",
       "5       5   \n",
       "6       5   \n",
       "7       5   \n",
       "8       5   \n",
       "9       5   \n",
       "\n",
       "                                                                                               Content  \\\n",
       "0                                                                                       It just works!   \n",
       "1  –í —Ü–µ–ª–æ–º —É–¥–æ–±–Ω–æ–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ...–∏–∑ –º–∏–Ω—É—Å–æ–≤ —Ö–æ—Ç—è—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –¥–æ—Å—Ç—É–ø –∫ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º –≤ —Ç...   \n",
       "2                                                                                          –û—Ç–ª–∏—á–Ω–æ –≤—Å–µ   \n",
       "3       –°—Ç–∞–ª –∑–∞–≤–∏—Å–∞—Ç—å –Ω–∞ 1% —Ä–∞–±–æ—Ç—ã –∞–Ω—Ç–∏–≤–∏—Ä—É—Å–∞. –î–∞–ª—å—à–µ –Ω–∏–∫—É–¥–∞. –†–∞–Ω–µ–µ –±–æ–ª—å—à–µ –≥–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ.   \n",
       "4                                                                       –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ—Ç –±—ã—Å—Ç—Ä–æ.   \n",
       "5                                                                                  –í—Å—ë —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º üëçüëçüëç   \n",
       "6                                                                            –û—á–µ–Ω—å —É–¥–æ–±–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.   \n",
       "7                                                                                       –í—Å–µ —É—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç   \n",
       "8                   –£ –º–µ–Ω—è —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ —á–µ—Ç–∫–æ. –í –æ—Ç–ª–∏—á–∏–∏ –æ—Ç –±–∞–Ω–∫–æ–º–∞—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—é—Ç –∏ —Ç—É–ø—è—Ç   \n",
       "9                                                                                    –û—á–µ–Ω—å –≤—Å–µ —Ö–æ—Ä–æ—à–æüëç   \n",
       "\n",
       "         Date  \n",
       "0  2017-08-14  \n",
       "1  2017-08-14  \n",
       "2  2017-08-14  \n",
       "3  2017-08-14  \n",
       "4  2017-08-14  \n",
       "5  2017-08-14  \n",
       "6  2017-08-14  \n",
       "7  2017-08-14  \n",
       "8  2017-08-14  \n",
       "9  2017-08-14  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('–æ—Ç–∑—ã–≤—ã –∑–∞ –ª–µ—Ç–æ.xls')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae8cca",
   "metadata": {},
   "source": [
    "#### –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72774633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
    "max_words = 200\n",
    "# –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "max_len = 140\n",
    "num_classes = 1\n",
    "\n",
    "# Training\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abcf0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "    \n",
    "df['Content'] = df['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7320a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>it just works</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>—Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å—à–æ–π –¥–æ—Å—Ç—É–ø –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –¥–∞–Ω–Ω—ã–µ —Ç–µ–ª–µ—Ñ–æ–Ω–µ–ø—Ä–∏—Ö–æ–¥–∏—Ç—å—Å—è...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>–æ—Ç–ª–∏—á–Ω–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>–∑–∞–≤–∏—Å–∞—Ç—å 1 —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω–æ –Ω–æ—Ä–º–∞ üëçüëçüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>—É–¥–æ–±–Ω—ã–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>—É—Å—Ç—Ä–∞–∏–≤–∞—Ç—å</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>—Ä–∞–±–æ—Ç–∞—Ç—å —á—ë—Ç–∫–æ –æ—Ç–ª–∏—á–∏–µ –±–∞–Ω–∫–æ–º–∞—Ç –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å —Ç—É–ø–∏—Ç—å</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>—Ö–æ—Ä–æ—à–æüëç</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  \\\n",
       "0       5   \n",
       "1       4   \n",
       "2       5   \n",
       "3       5   \n",
       "4       5   \n",
       "5       5   \n",
       "6       5   \n",
       "7       5   \n",
       "8       5   \n",
       "9       5   \n",
       "\n",
       "                                                                                               Content  \\\n",
       "0                                                                                        it just works   \n",
       "1  —Ü–µ–ª–æ–µ —É–¥–æ–±–Ω–æ–Ω–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–∏–∑ –º–∏–Ω—É—Å —Ö–æ—Ç–µ—Ç—å –±–æ–ª—å—à–æ–π –¥–æ—Å—Ç—É–ø –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –¥–∞–Ω–Ω—ã–µ —Ç–µ–ª–µ—Ñ–æ–Ω–µ–ø—Ä–∏—Ö–æ–¥–∏—Ç—å—Å—è...   \n",
       "2                                                                                              –æ—Ç–ª–∏—á–Ω–æ   \n",
       "3                                             –∑–∞–≤–∏—Å–∞—Ç—å 1 —Ä–∞–±–æ—Ç–∞ –∞–Ω—Ç–∏–≤–∏—Ä—É—Å —Ä–∞–Ω–µ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ   \n",
       "4                                                                               —É–¥–æ–±–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±—ã—Å—Ç—Ä–æ   \n",
       "5                                                                                     —É–¥–æ–±–Ω–æ –Ω–æ—Ä–º–∞ üëçüëçüëç   \n",
       "6                                                                                   —É–¥–æ–±–Ω—ã–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ   \n",
       "7                                                                                           —É—Å—Ç—Ä–∞–∏–≤–∞—Ç—å   \n",
       "8                                                —Ä–∞–±–æ—Ç–∞—Ç—å —á—ë—Ç–∫–æ –æ—Ç–ª–∏—á–∏–µ –±–∞–Ω–∫–æ–º–∞—Ç –≤–µ—á–Ω–æ –∑–∞–≤–∏—Å–∞—Ç—å —Ç—É–ø–∏—Ç—å   \n",
       "9                                                                                              —Ö–æ—Ä–æ—à–æüëç   \n",
       "\n",
       "         Date  \n",
       "0  2017-08-14  \n",
       "1  2017-08-14  \n",
       "2  2017-08-14  \n",
       "3  2017-08-14  \n",
       "4  2017-08-14  \n",
       "5  2017-08-14  \n",
       "6  2017-08-14  \n",
       "7  2017-08-14  \n",
       "8  2017-08-14  \n",
       "9  2017-08-14  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f37629a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f19dcff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (16527, 3), Test: (3305, 3), Val: (827, 3)\n"
     ]
    }
   ],
   "source": [
    "# –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.2)\n",
    "print(f'Train: {df_train.shape}, Test: {df_test.shape}, Val: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25d6cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f7053a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\s–Ω–µ\", \"–Ω–µ\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37ff4a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
    "df_val['Content'] = df_val['Content'].apply(preprocess_text)\n",
    "df_test['Content'] = df_test['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbcddeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"Content\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaf0041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16381821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c0d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8b3e4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ',\n",
       " '—É–¥–æ–±–Ω–æ',\n",
       " '—Ä–∞–±–æ—Ç–∞—Ç—å',\n",
       " '—É–¥–æ–±–Ω—ã–π',\n",
       " '–æ—Ç–ª–∏—á–Ω–æ',\n",
       " '–Ω—Ä–∞–≤–∏—Ç—å—Å—è',\n",
       " '—Ö–æ—Ä–æ—à–∏–π',\n",
       " '–æ—Ç–ª–∏—á–Ω—ã–π',\n",
       " '—Ç–µ–ª–µ—Ñ–æ–Ω',\n",
       " '—Å—É–ø–µ—Ä']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e10f6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48769c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ø–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç –≤–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    # –¥–æ–±–∞–≤–ª—è–µ–º –Ω—É–ª–∏ –¥–æ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e013bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Content\"]], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"Content\"]], dtype=np.int32)\n",
    "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee7ec16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Rating\"] = df_train[\"Rating\"] - 1\n",
    "df_val[\"Rating\"] = df_val[\"Rating\"] - 1\n",
    "df_test[\"Rating\"] = df_test[\"Rating\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "092df3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, 49, 43, 22], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654503ba",
   "metadata": {},
   "source": [
    "#### –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–π tf.keras.layers.Embedding –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–Ω—É —Ç–æ –µ—Å—Ç—å –≤–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞—Ç—å —Å –≤–µ—Å–∞–º–∏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eecf1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82c5e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (1.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdc4cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.4.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from keras==2.4.3) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from keras==2.4.3) (1.21.0)\n",
      "Requirement already satisfied: h5py in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from keras==2.4.3) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from keras==2.4.3) (6.0)\n"
     ]
    }
   ],
   "source": [
    "# from keras.utils.data_utils import pad_sequences\n",
    "!pip install keras==2.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef882e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.5.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.12.1)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.34.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.12)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.37.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.5.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.15.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp39-cp39-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (2.8.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (3.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (1.1.2)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow==2.5.0) (0.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.33.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.0)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.0\n",
      "    Uninstalling numpy-1.21.0:\n",
      "      Successfully uninstalled numpy-1.21.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "bokeh 2.4.2 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "594fb436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dca in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (0.3.3)\n",
      "Requirement already satisfied: numpy>=1.7 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (1.19.5)\n",
      "Requirement already satisfied: tensorflow>=2.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (2.5.0)\n",
      "Requirement already satisfied: kopt in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (0.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (1.15.0)\n",
      "Requirement already satisfied: scanpy in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (1.9.1)\n",
      "Requirement already satisfied: keras<2.6,>=2.4 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (2.4.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (1.0.2)\n",
      "Requirement already satisfied: pandas in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (1.2.0)\n",
      "Requirement already satisfied: h5py in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from dca) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from keras<2.6,>=2.4->dca) (6.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from keras<2.6,>=2.4->dca) (1.7.3)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (1.34.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (3.3.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (2.8.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (0.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (3.19.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (0.37.1)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (1.1.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.0->dca) (2.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (1.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (61.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow>=2.0->dca) (2.27.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->dca) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->dca) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->dca) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.0->dca) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0->dca) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->dca) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->dca) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->dca) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0->dca) (3.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.0->dca) (3.2.0)\n",
      "Requirement already satisfied: hyperopt in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from kopt->dca) (0.2.7)\n",
      "Requirement already satisfied: future in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from kopt->dca) (0.18.2)\n",
      "Requirement already satisfied: matplotlib in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from kopt->dca) (3.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->dca) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->dca) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from hyperopt->kopt->dca) (4.64.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from hyperopt->kopt->dca) (2.7.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from hyperopt->kopt->dca) (2.0.0)\n",
      "Requirement already satisfied: py4j in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from hyperopt->kopt->dca) (0.10.9.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging>=20.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->kopt->dca) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->kopt->dca) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->kopt->dca) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->kopt->dca) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->kopt->dca) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->kopt->dca) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->kopt->dca) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from pandas->dca) (2021.3)\n",
      "Requirement already satisfied: statsmodels>=0.10.0rc2 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (0.13.2)\n",
      "Requirement already satisfied: umap-learn>=0.3.10 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (0.5.3)\n",
      "Requirement already satisfied: numba>=0.41.0 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (0.55.1)\n",
      "Requirement already satisfied: natsort in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (8.1.0)\n",
      "Requirement already satisfied: session-info in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (1.0.0)\n",
      "Requirement already satisfied: anndata>=0.7.4 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (0.8.0)\n",
      "Requirement already satisfied: seaborn in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (0.11.2)\n",
      "Requirement already satisfied: patsy in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from scanpy->dca) (0.5.2)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from numba>=0.41.0->scanpy->dca) (0.38.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from umap-learn>=0.3.10->scanpy->dca) (0.5.7)\n",
      "Requirement already satisfied: stdlib-list in /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages (from session-info->scanpy->dca) (0.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3167bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pkg_resources\n",
    "# print(f\"dca v{pkg_resources.get_distribution('dca').version}\")\n",
    "# print(f\"keras v{pkg_resources.get_distribution('keras').version}\")\n",
    "\n",
    "# from dca.api import dca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "291a00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Bidirectional, LSTM, SpatialDropout1D, concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, Flatten, MaxPooling1D\n",
    "from keras.layers import GlobalMaxPool1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "# import tf.keras.utils.custom_object_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d947175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/64/g6jhnpm16ql1vgrrbrbd_yd00000gn/T/ipykernel_22782/3914372017.py\", line 4, in <cell line: 4>\n",
      "    model.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 522, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 223, in add\n",
      "    output_tensor = layer(self.outputs[0])\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/wrappers.py\", line 581, in __call__\n",
      "    return super(Bidirectional, self).__call__(inputs, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 945, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1083, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 816, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 856, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/wrappers.py\", line 694, in call\n",
      "    y = self.forward_layer(forward_inputs,\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 660, in __call__\n",
      "    return super(RNN, self).__call__(inputs, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1006, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent_v2.py\", line 1139, in call\n",
      "    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 860, in _process_inputs\n",
      "    initial_state = self.get_initial_state(inputs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 642, in get_initial_state\n",
      "    init_state = get_initial_state_fn(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 2508, in get_initial_state\n",
      "    return list(_generate_zero_filled_state_for_cell(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 2990, in _generate_zero_filled_state_for_cell\n",
      "    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 3006, in _generate_zero_filled_state\n",
      "    return tf.nest.map_structure(create_zeros, state_size)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 3003, in create_zeros\n",
      "    return tf.zeros(init_state_size, dtype=dtype)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2911, in wrapped\n",
      "    tensor = fun(*args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2960, in zeros\n",
      "    output = _constant_if_small(zero, shape, dtype, name)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2896, in _constant_if_small\n",
      "    if np.prod(shape) < 1000:\n",
      "  File \"<__array_function__ internals>\", line 5, in prod\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 3051, in prod\n",
      "    >>> np.prod([1.,2.])\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 867, in __array__\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: Cannot convert a symbolic Tensor (bidirectional_2/forward_lstm_2/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a4e35",
   "metadata": {},
   "source": [
    "**–ë—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–Ω–∞ –∑–∞ –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –æ—à–∏–±–∫–∏. –ù–∏–∫–∞–∫ –Ω–µ –º–æ–≥—É –ø–æ–Ω—è—Ç—å —á—Ç–æ –Ω–µ —Ç–∞–∫ –¥–µ–ª–∞—é.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc6d95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "y_train = tf.keras.utils.to_categorical(df_train[\"Rating\"], num_classes=num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(df_val[\"Rating\"], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e25c5338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "model.compile(loss='pad_sequences',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56b95cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 18:54:00.368239: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-06-20 18:54:00.368251: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-06-20 18:54:00.368333: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-06-20 18:54:00.548414: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:771 train_step  *\n        loss = self.compiled_loss(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:184 __call__  *\n        self.build(y_pred)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:133 build  *\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 map_structure  **\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:273 _get_loss_object\n        loss = losses_mod.get(loss)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2065 get\n        return deserialize(identifier)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2020 deserialize\n        return deserialize_keras_object(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py:698 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: pad_sequences. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# class CustomLayer(keras.layers.Layer):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     def __init__(self, a):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#         self.var = tf.Variable(a, name=\"var_a\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#     serialized_layer, custom_objects={\"CustomLayer\": CustomLayer}\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1158\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1153\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1154\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1155\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1156\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1157\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1158\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1159\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1160\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    767\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3050\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3050\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3444\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3441\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3444\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3279\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3274\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3276\u001b[0m ]\n\u001b[1;32m   3277\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3278\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3282\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3287\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3288\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3291\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3292\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3293\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3294\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3295\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3296\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:999\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 999\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1004\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:672\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    670\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 672\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    985\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    987\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:771 train_step  *\n        loss = self.compiled_loss(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:184 __call__  *\n        self.build(y_pred)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:133 build  *\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 map_structure  **\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:273 _get_loss_object\n        loss = losses_mod.get(loss)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2065 get\n        return deserialize(identifier)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2020 deserialize\n        return deserialize_keras_object(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py:698 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: pad_sequences. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "# class CustomLayer(keras.layers.Layer):\n",
    "#     def __init__(self, a):\n",
    "#         self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "#     def call(self, inputs, training=False):\n",
    "#         if training:\n",
    "#             return inputs * self.var\n",
    "#         else:\n",
    "#             return inputs\n",
    "\n",
    "#     def get_config(self):\n",
    "#         return {\"a\": self.var.numpy()}\n",
    "\n",
    "#     # There's actually no need to define `from_config` here, since returning\n",
    "#     # `cls(**config)` is the default behavior.\n",
    "#     @classmethod\n",
    "#     def from_config(cls, config):\n",
    "#         return cls(**config)\n",
    "\n",
    "\n",
    "# layer = CustomLayer(5)\n",
    "# layer.var.assign(2)\n",
    "\n",
    "# serialized_layer = keras.layers.serialize(layer)\n",
    "# new_layer = keras.layers.deserialize(\n",
    "#     serialized_layer, custom_objects={\"CustomLayer\": CustomLayer}\n",
    "# )\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64cf4449",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1298 test_function  *\n        return step_function(self, iterator)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1282 run_step  *\n        outputs = model.test_step(data)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1243 test_step  *\n        self.compiled_loss(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:184 __call__  *\n        self.build(y_pred)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:133 build  *\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 map_structure  **\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:273 _get_loss_object\n        loss = losses_mod.get(loss)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2065 get\n        return deserialize(identifier)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2020 deserialize\n        return deserialize_keras_object(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py:698 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: pad_sequences. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest score:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1464\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1463\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1464\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1465\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1466\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    767\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3050\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3050\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3444\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3441\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3444\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3279\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3274\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3276\u001b[0m ]\n\u001b[1;32m   3277\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3278\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3282\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3287\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3288\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3291\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3292\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3293\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3294\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3295\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3296\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:999\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 999\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1004\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:672\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    670\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 672\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    985\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    987\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1298 test_function  *\n        return step_function(self, iterator)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1282 run_step  *\n        outputs = model.test_step(data)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1243 test_step  *\n        self.compiled_loss(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:184 __call__  *\n        self.build(y_pred)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:133 build  *\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 map_structure  **\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py:867 <listcomp>\n        structure[0], [func(*x) for x in entries],\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py:273 _get_loss_object\n        loss = losses_mod.get(loss)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2065 get\n        return deserialize(identifier)\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/losses.py:2020 deserialize\n        return deserialize_keras_object(\n    /Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py:698 deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: pad_sequences. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7b295",
   "metadata": {},
   "source": [
    "#### –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å tf.keras.layers.Embedding –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –≤–∑—è—Ç—å –∫ –ø—Ä–∏–º–µ—Ä—É —Å https://rusvectores.org/ru/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "607adcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_w2v = KeyedVectors.load_word2vec_format('https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acee258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_w2v_txt(txt, max_len = 100):\n",
    "    sent_w2v = []\n",
    "    zero_point = np.zeros(300)\n",
    "    txt = txt.split()\n",
    "   \n",
    "    for i in range(max_len):\n",
    "        try:\n",
    "            word = ru_w2v[txt[i]]\n",
    "        except:\n",
    "            word = zero_point\n",
    "        sent_w2v.append(word)\n",
    "    return np.array(sent_w2v)\n",
    "\n",
    "max_len = 50\n",
    "df['w2v'] = df['Content'].apply(code_w2v_txt, max_len = max_len)\n",
    "del(ru_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99b6e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['w2v'].values)\n",
    "X = np.array(X)\n",
    "y = df['Rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "588033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "379cd59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(y_train) \n",
    "test_enc_labels = le.transform(y_test)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10d3596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/64/g6jhnpm16ql1vgrrbrbd_yd00000gn/T/ipykernel_22782/1165963707.py\", line 5, in <cell line: 5>\n",
      "    x = Bidirectional(LSTM(units=7, return_sequences=True))(dropout_embeds)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/wrappers.py\", line 581, in __call__\n",
      "    return super(Bidirectional, self).__call__(inputs, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 945, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1083, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 816, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 856, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/wrappers.py\", line 694, in call\n",
      "    y = self.forward_layer(forward_inputs,\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 660, in __call__\n",
      "    return super(RNN, self).__call__(inputs, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1006, in __call__\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent_v2.py\", line 1139, in call\n",
      "    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 860, in _process_inputs\n",
      "    initial_state = self.get_initial_state(inputs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 642, in get_initial_state\n",
      "    init_state = get_initial_state_fn(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 2508, in get_initial_state\n",
      "    return list(_generate_zero_filled_state_for_cell(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 2990, in _generate_zero_filled_state_for_cell\n",
      "    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 3006, in _generate_zero_filled_state\n",
      "    return tf.nest.map_structure(create_zeros, state_size)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py\", line 867, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/nest.py\", line 867, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/keras/layers/recurrent.py\", line 3003, in create_zeros\n",
      "    return tf.zeros(init_state_size, dtype=dtype)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2911, in wrapped\n",
      "    tensor = fun(*args, **kwargs)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2960, in zeros\n",
      "    output = _constant_if_small(zero, shape, dtype, name)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2896, in _constant_if_small\n",
      "    if np.prod(shape) < 1000:\n",
      "  File \"<__array_function__ internals>\", line 5, in prod\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 3051, in prod\n",
      "    >>> a = np.array([[1, 2, 3], [4, 5, 6]])\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 867, in __array__\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: Cannot convert a symbolic Tensor (bidirectional_1/forward_lstm_1/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/alenakukhta/opt/anaconda3/lib/python3.9/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df.Rating.unique())\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "dropout_embeds = SpatialDropout1D(0.05)(inputs)\n",
    "x = Bidirectional(LSTM(units=7, return_sequences=True))(dropout_embeds)\n",
    "pooled_avg_sequences = GlobalAveragePooling1D()(x)\n",
    "pooled_max_sequences = GlobalMaxPooling1D()(x)\n",
    "concated = concatenate([pooled_avg_sequences, pooled_max_sequences])\n",
    "dense_intermediate = Dense(64, activation='elu')(concated)\n",
    "x = Dense(num_classes, activation='sigmoid')(dense_intermediate)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "model.summary()\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab033292",
   "metadata": {},
   "source": [
    "**–ë—É–¥—É –±–ª–∞–≥–æ–¥–∞—Ä–Ω–∞ –∑–∞ –¥–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä –æ—à–∏–±–∫–∏. –ù–∏–∫–∞–∫ –Ω–µ –º–æ–≥—É –ø–æ–Ω—è—Ç—å —á—Ç–æ –Ω–µ —Ç–∞–∫ –¥–µ–ª–∞—é.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f4ca382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 18:59:07.449371: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-06-20 18:59:07.449386: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-06-20 18:59:07.449900: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tensorboard\u001b[38;5;241m=\u001b[39mTensorBoard(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m'\u001b[39m, write_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, write_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m early_stopping\u001b[38;5;241m=\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_enc_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1080\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;66;03m# Legacy graph support is contained in `training_v1.Model`.\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m version_utils\u001b[38;5;241m.\u001b[39mdisallow_legacy_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1080\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_compile_was_called\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1082\u001b[0m _disallow_inside_tf_function(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2668\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2663\u001b[0m   \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   2664\u001b[0m   \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   2665\u001b[0m   \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   2666\u001b[0m   \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   2667\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 2668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2669\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2670\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, train_enc_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a77f73b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_enc_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest score:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1411\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1409\u001b[0m base_layer\u001b[38;5;241m.\u001b[39mkeras_api_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1410\u001b[0m version_utils\u001b[38;5;241m.\u001b[39mdisallow_legacy_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1411\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_compile_was_called\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1413\u001b[0m _disallow_inside_tf_function(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2668\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2663\u001b[0m   \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   2664\u001b[0m   \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   2665\u001b[0m   \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   2666\u001b[0m   \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   2667\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 2668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2669\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2670\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, test_enc_labels)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adf26da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(inputs)\n",
    "l_pool1 = MaxPooling1D(2)(l_cov1)\n",
    "l_cov2 =Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(2)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(5)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(64, activation='softmax')(l_dense)\n",
    "preds = Dense(num_classes, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=preds)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6758fb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 18:59:50.213178: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-06-20 18:59:50.213191: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-06-20 18:59:50.213590: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 2/26 [=>............................] - ETA: 3s - loss: 1.6092 - accuracy: 0.2690  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 18:59:55.895907: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-06-20 18:59:55.895923: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-06-20 18:59:56.010380: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-06-20 18:59:56.011797: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-06-20 18:59:56.020234: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2022_06_20_18_59_56\n",
      "2022-06-20 18:59:56.020907: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/train/plugins/profile/2022_06_20_18_59_56/iMac-Alena.local.trace.json.gz\n",
      "2022-06-20 18:59:56.023872: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/train/plugins/profile/2022_06_20_18_59_56\n",
      "2022-06-20 18:59:56.024168: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/train/plugins/profile/2022_06_20_18_59_56/iMac-Alena.local.memory_profile.json.gz\n",
      "2022-06-20 18:59:56.025191: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/train/plugins/profile/2022_06_20_18_59_56Dumped tool data for xplane.pb to ./logs/train/plugins/profile/2022_06_20_18_59_56/iMac-Alena.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/train/plugins/profile/2022_06_20_18_59_56/iMac-Alena.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/train/plugins/profile/2022_06_20_18_59_56/iMac-Alena.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/train/plugins/profile/2022_06_20_18_59_56/iMac-Alena.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/train/plugins/profile/2022_06_20_18_59_56/iMac-Alena.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 8s 127ms/step - loss: 1.6030 - accuracy: 0.6228 - val_loss: 1.5836 - val_accuracy: 0.7049\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, train_enc_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8482b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 1s 4ms/step - loss: 1.5834 - accuracy: 0.7086\n",
      "\n",
      "\n",
      "Test score: 1.5834083557128906\n",
      "Test accuracy: 0.7086156606674194\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, test_enc_labels)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
